version: "3.8"

networks:
  bigdata_net:
    driver: bridge

volumes:
  postgres_data:
  mysql_data:

# =========================================================
# üß© Common Airflow Configuration
# =========================================================
x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile.airflow
  environment:
    # Core Airflow
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__FERNET_KEY: 'M8XP8zJEvdBQu6WTvM1ruAC_gXqbNZZYQ5st_8K7RfI='
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow

    # ‚úÖ REST API Authentication (Basic Auth)
    AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
    AIRFLOW__WEBSERVER__RBAC: 'True'

    # Webserver Configuration
    AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8082
    AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
    AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: 'True'
    AIRFLOW__WEBSERVER__SECRET_KEY: 'airflow_secret_key_123'

    # Logging
    AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
    AIRFLOW__LOGGING__REMOTE_LOGGING: 'False'
    AIRFLOW__LOGGING__LOG_LEVEL: INFO

    # Email Configuration
    AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
    AIRFLOW__SMTP__SMTP_PORT: 587
    AIRFLOW__SMTP__SMTP_STARTTLS: 'True'
    AIRFLOW__SMTP__SMTP_SSL: 'False'
    AIRFLOW__SMTP__SMTP_USER: abdulllah02003@gmail.com
    AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD:-rybvwzzjdemgzygm}
    AIRFLOW__SMTP__SMTP_MAIL_FROM: abdulllah02003@gmail.com

    # Timezone
    TZ: "UTC"

  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./dags/keys:/opt/airflow/dags/keys
    - /var/run/docker.sock:/var/run/docker.sock
    - /etc/localtime:/etc/localtime:ro

  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  networks:
    - bigdata_net

# =========================================================
# üóÑÔ∏è Services
# =========================================================
services:
  postgres:
    image: postgres:13
    container_name: postgres
    networks:
      - bigdata_net
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - /etc/localtime:/etc/localtime:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 10

  redis:
    image: redis:latest
    container_name: redis
    networks:
      - bigdata_net
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8082:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 10

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 10

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    networks:
      - bigdata_net
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "echo stat | nc localhost 2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    networks:
      - bigdata_net
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks:
      - bigdata_net
    ports:
      - "8085:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      kafka:
        condition: service_healthy
      zookeeper:
        condition: service_healthy

  jobmanager:
    build:
      context: .
      dockerfile: Dockerfile.flink3
    container_name: jobmanager
    networks:
      - bigdata_net
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TZ=UTC
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8081/"]
      interval: 30s
      timeout: 10s
      retries: 5

  taskmanager:
    build:
      context: .
      dockerfile: Dockerfile.flink3
    container_name: taskmanager
    networks:
      - bigdata_net
    depends_on:
      jobmanager:
        condition: service_healthy
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TZ=UTC

  mysql:
    image: mysql:8.0
    container_name: mysql
    networks:
      - bigdata_net
    environment:
      MYSQL_ROOT_PASSWORD: rootpass
      MYSQL_DATABASE: booksdb
      MYSQL_USER: booksuser
      MYSQL_PASSWORD: bookspass
    ports:
      - "3307:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 5

  spark-master:
    image: apache/spark:3.5.1
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"
    command: >
      /bin/bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    networks:
      - bigdata_net
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 5

  spark-worker:
    image: apache/spark:3.5.1
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8083:8081"
    command: >
      /bin/bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    networks:
      - bigdata_net
